{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid-19 Risk 2022\n",
    "Predict patient outcomes in 44M reported US Covid-19 cases from basic demographics.\n",
    "\n",
    "## Goal\n",
    "Predict the risk of death from basic demographic information.\n",
    "\n",
    "## Data\n",
    "This dataset was downloaded from the CDC website and contains most of confirmed Covid-19 cases in the US since the beginning of the pandemic. Anonymized patient data contains a number of demographic features and risk factors, along with whether the patient died.\n",
    "\n",
    "## Train/Test Split\n",
    "The training dataset consists of all confirmed covid-19 patients before Oct 1st, 2021. The test dataset contains patients from Oct 2022 to Jan 18 2022. Half of the test set is used to calculate the leaderboard, while the other half is used for the final evaluation.\n",
    "\n",
    "## Missing Data\n",
    "The data is not fully sanitized. Many patients have missing data. \n",
    "\n",
    "## Evaluation Metric\n",
    "Predictions are evaluated using the area under the receiver operator characteristic (AUROC or AUC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV;\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36225855, 12)\n",
      "(2594412, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_month</th>\n",
       "      <th>res_state</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>labconfirmed_yn</th>\n",
       "      <th>symptomatic_yn</th>\n",
       "      <th>hosp_yn</th>\n",
       "      <th>icu_yn</th>\n",
       "      <th>death_yn</th>\n",
       "      <th>underlying_conditions_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_month res_state age_group  sex race ethnicity  labconfirmed_yn  \\\n",
       "0    2020-01        NY       NaN  NaN  NaN       NaN             True   \n",
       "\n",
       "  symptomatic_yn  hosp_yn icu_yn  death_yn  underlying_conditions_yn  \n",
       "0            NaN      NaN    NaN       0.0                       NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data.\n",
    "fields = ['case_month', 'res_state', 'age_group', 'sex', 'race', 'ethnicity', 'labconfirmed_yn', \n",
    "          'symptomatic_yn', 'hosp_yn', 'icu_yn', 'underlying_conditions_yn', 'death_yn']\n",
    "# ignore state_fips_code, res_county, county_fips_code, case_positive_specimen_interval, case_onset_interval, process, exposure_yn\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    'train.csv', usecols=fields, \n",
    "    dtype={ 'labconfirmed_yn': bool, 'symptomatic_yn': object, 'icu_yn': object }\n",
    ") # Can read from zip files directly.\n",
    "\n",
    "# Load test data.\n",
    "df_test = pd.read_csv(\n",
    "    'test.csv', usecols=fields[:-1], \n",
    "    dtype={ 'labconfirmed_yn': bool, 'symptomatic_yn': object, 'icu_yn': object }\n",
    ")\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nunique\n",
      "case_month                  21\n",
      "res_state                   54\n",
      "age_group                    5\n",
      "sex                          4\n",
      "race                         8\n",
      "ethnicity                    4\n",
      "labconfirmed_yn              2\n",
      "symptomatic_yn               3\n",
      "hosp_yn                      2\n",
      "icu_yn                       3\n",
      "death_yn                     2\n",
      "underlying_conditions_yn     2\n",
      "dtype: int64\n",
      "\n",
      "case_month\n",
      "['2020-01' '2020-02' '2020-03' '2020-04' '2020-05' '2020-06' '2020-07'\n",
      " '2020-08' '2020-09' '2020-10' '2020-11' '2020-12' '2021-01' '2021-02'\n",
      " '2021-03' '2021-04' '2021-05' '2021-06' '2021-07' '2021-08' '2021-09']\n",
      "\n",
      "res_state\n",
      "['NY' 'NC' 'NJ' 'IA' 'GA' 'NV' 'TX' 'FL' 'CA' 'TN' 'SC' 'UT' 'MO' 'WI'\n",
      " 'OH' 'WA' 'MI' nan 'CO' 'CT' 'IN' 'MA' 'PR' 'MD' 'AL' 'ME' 'SD' 'AZ' 'KY'\n",
      " 'NM' 'KS' 'NE' 'PA' 'VA' 'IL' 'DC' 'LA' 'AR' 'MS' 'OR' 'MN' 'VT' 'MT'\n",
      " 'ID' 'AK' 'OK' 'HI' 'NH' 'ND' 'WY' 'RI' 'DE' 'WV' 'VI' 'GU']\n",
      "\n",
      "age_group\n",
      "[nan '65+ years' '18 to 49 years' '50 to 64 years' '0 - 17 years'\n",
      " 'Missing']\n",
      "\n",
      "sex\n",
      "[nan 'Male' 'Female' 'Unknown' 'Missing']\n",
      "\n",
      "race\n",
      "[nan 'White' 'Multiple/Other' 'Black' 'Unknown' 'Asian' 'Missing'\n",
      " 'American Indian/Alaska Native' 'Native Hawaiian/Other Pacific Islander']\n",
      "\n",
      "ethnicity\n",
      "[nan 'Non-Hispanic/Latino' 'Unknown' 'Hispanic/Latino' 'Missing']\n",
      "\n",
      "labconfirmed_yn\n",
      "[ True False]\n",
      "\n",
      "symptomatic_yn\n",
      "[nan '1' '0' 'nul']\n",
      "\n",
      "hosp_yn\n",
      "[nan  0.  1.]\n",
      "\n",
      "icu_yn\n",
      "[nan '1' '0' 'nul']\n",
      "\n",
      "death_yn\n",
      "[ 0. nan  1.]\n",
      "\n",
      "underlying_conditions_yn\n",
      "[nan  1.  0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the num of unique values\n",
    "print(f\"nunique\\n{df_train.nunique()}\\n\")\n",
    "# See the unique values\n",
    "for col in df_train:\n",
    "    print(f\"{col}\\n{df_train[col].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.629269342229879\n"
     ]
    }
   ],
   "source": [
    "# See % of deaths\n",
    "deaths = df_train.dropna(subset=['death_yn'])\n",
    "total = deaths.shape[0]\n",
    "deaths = deaths[ (deaths.death_yn == 1) ]\n",
    "print(deaths.shape[0] / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_month\n",
      "2020-12    64781\n",
      "2020-04    56784\n",
      "2020-11    42270\n",
      "2021-01    42146\n",
      "2020-03    18865\n",
      "2020-05    17978\n",
      "2021-08    17879\n",
      "2020-07    15139\n",
      "2020-10    14932\n",
      "2021-09    12845\n",
      "Name: case_month, dtype: int64\n",
      "\n",
      "res_state\n",
      "CA    60407\n",
      "FL    44609\n",
      "NY    36881\n",
      "IL    29430\n",
      "NJ    16839\n",
      "PA    16192\n",
      "OH    15592\n",
      "MA    14455\n",
      "AZ    14377\n",
      "MI     7713\n",
      "Name: res_state, dtype: int64\n",
      "\n",
      "age_group\n",
      "65+ years         312110\n",
      "50 to 64 years     32812\n",
      "18 to 49 years      6559\n",
      "0 - 17 years          13\n",
      "Missing                4\n",
      "Name: age_group, dtype: int64\n",
      "\n",
      "sex\n",
      "Male       188259\n",
      "Female     162556\n",
      "Unknown       133\n",
      "Missing         1\n",
      "Name: sex, dtype: int64\n",
      "\n",
      "race\n",
      "White                                     263440\n",
      "Black                                      39095\n",
      "Asian                                      10906\n",
      "Unknown                                    10122\n",
      "Missing                                     8335\n",
      "Multiple/Other                              1812\n",
      "American Indian/Alaska Native                929\n",
      "Native Hawaiian/Other Pacific Islander        12\n",
      "Name: race, dtype: int64\n",
      "\n",
      "ethnicity\n",
      "Non-Hispanic/Latino    259779\n",
      "Hispanic/Latino         45018\n",
      "Unknown                 22838\n",
      "Missing                  6193\n",
      "Name: ethnicity, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Out of 352,187 deaths, see most common case_month\n",
    "print(f\"case_month\\n{deaths.case_month.value_counts()[:10]}\\n\")\n",
    "# most common res_state\n",
    "print(f\"res_state\\n{deaths.res_state.value_counts()[:10]}\\n\")\n",
    "# most common age_group\n",
    "print(f\"age_group\\n{deaths.age_group.value_counts()}\\n\")\n",
    "# most common sex\n",
    "print(f\"sex\\n{deaths.sex.value_counts()}\\n\")\n",
    "# most common race\n",
    "print(f\"race\\n{deaths.race.value_counts()}\\n\")\n",
    "# most common ethnicity\n",
    "print(f\"ethnicity\\n{deaths.ethnicity.value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_month                   0.000000\n",
      "res_state                    0.002542\n",
      "age_group                    1.097434\n",
      "sex                          3.007832\n",
      "race                        15.793333\n",
      "ethnicity                   18.604105\n",
      "labconfirmed_yn              0.000000\n",
      "symptomatic_yn              51.848121\n",
      "hosp_yn                     52.816078\n",
      "icu_yn                      94.681083\n",
      "death_yn                    63.024028\n",
      "underlying_conditions_yn    94.207518\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# See % missing data\n",
    "missing = df_train.isna().sum() / df_train.shape[0] * 100\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3219293, 11)\n"
     ]
    }
   ],
   "source": [
    "# use only the most recent case_month\n",
    "df_train = df_train.loc[df_train['case_month'] == '2021-09']\n",
    "df_train.drop(columns=['case_month'], inplace=True) # drop case_month\n",
    "print(f\"shape: {df_train.shape}\")\n",
    "\n",
    "# drop rows w/ nan age_group, sex, res_state\n",
    "df_train.dropna(subset=['age_group', 'sex', 'res_state'], inplace=True)\n",
    "# drop rows w/ missing age_group\n",
    "df_train.drop(df_train[df_train['age_group'] == 'Missing'].index, inplace=True)\n",
    "# drop rows w/ missing or unknown sex\n",
    "df_train.drop(df_train[ (df_train['sex'] == 'Unknown') | (df_train['sex'] == 'Missing') ].index, inplace=True)\n",
    "\n",
    "# impute nan data\n",
    "df_train.replace(\n",
    "    {'death_yn':{np.nan:0}, # Assume no info means survived.\n",
    "     'symptomatic_yn':{np.nan:0, 'nul':0, '0':0, '1':1},\n",
    "     'hosp_yn':{np.nan:0},\n",
    "     'icu_yn':{np.nan:0, 'nul':0, '0':0, '1':1},\n",
    "     'underlying_conditions_yn':{np.nan:0}},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# encode sex, race, ethnicity\n",
    "\n",
    "# ethnicity: if Hispanic 1, else 0\n",
    "df_train.replace({'ethnicity': {'Hispanic/Latino': 1, 'Non-Hispanic/Latino': 0, 'Unknown': 0, 'Missing': 0, np.nan: 0} }, inplace=True)\n",
    "# sex: if Male 1, if Female 0\n",
    "df_train.replace({'sex':{'Male':1, 'Female':0}}, inplace=True)\n",
    "\n",
    "df_train.replace({'race':{'Unknown':np.nan, 'Missing':np.nan}}, inplace=True) # replace race Unknown, Missing w/ nan\n",
    "df_train.fillna(df_train.mode().iloc[0], inplace=True) # fill nan w/ most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['death_yn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for test data\n",
    "df_test.drop(columns=['case_month'], inplace=True)\n",
    "df_test.replace({\n",
    "    'age_group': {'Missing': np.nan},\n",
    "    'sex': {'Missing': np.nan, 'Unknown': np.nan},\n",
    "    'race': {'Unknown': np.nan, 'Missing': np.nan}\n",
    "}, inplace=True)\n",
    "df_test.replace(\n",
    "    {'symptomatic_yn':{np.nan:0, 'nul':0, '0':0, '1':1},\n",
    "     'hosp_yn':{np.nan:0},\n",
    "     'icu_yn':{np.nan:0, 'nul':0, '0':0, '1':1},\n",
    "     'underlying_conditions_yn':{np.nan:0}},\n",
    "    inplace=True\n",
    ") \n",
    "\n",
    "df_test.replace({'ethnicity': {'Hispanic/Latino': 1, 'Non-Hispanic/Latino': 0, 'Unknown': 0, 'Missing': 0, np.nan: 0} }, inplace=True)\n",
    "df_test.replace({'sex':{'Male':1, 'Female':0}}, inplace=True)\n",
    "df_test.fillna(df_test.mode().iloc[0], inplace=True) # fill nan w/ most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3062393, 68)\n"
     ]
    }
   ],
   "source": [
    "# Encode state and race as one-hot, age_group as ordinal\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(handle_unknown='ignore', sparse=False, dtype=bool), ['res_state', 'race']),\n",
    "    (OrdinalEncoder(dtype=np.int8), ['age_group']),\n",
    "    remainder='passthrough',\n",
    "    n_jobs=8,\n",
    "    verbose=True\n",
    ")\n",
    "df_train.drop(columns=['death_yn'], inplace=True)\n",
    "X = column_trans.fit_transform(df_train)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2594412, 68)\n",
      "[ColumnTransformer] ..... (3 of 3) Processing remainder, total=   0.0s\n",
      "[ColumnTransformer]  (2 of 3) Processing ordinalencoder, total=   0.6s\n",
      "[ColumnTransformer] . (1 of 3) Processing onehotencoder, total=   1.2s\n"
     ]
    }
   ],
   "source": [
    "# Repeat for test data\n",
    "X_test = column_trans.transform(df_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2296794, 68)\n",
      "(765599, 68)\n"
     ]
    }
   ],
   "source": [
    "# train, test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=.25, random_state=13); \n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters\n",
    "# learning_rate, n_estimators, max_depth, min_samples_split\n",
    "\n",
    "parameters = {\n",
    "    'learning_rate': [0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    'n_estimators': [8, 16, 32, 64, 100, 200],\n",
    "    'max_depth': np.linspace(1, 15, 8, endpoint=True), # 1, 3, ..., 15\n",
    "    'min_samples_split': np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "}\n",
    "clf = GradientBoostingClassifier();\n",
    "# scoring='f1_micro'\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=parameters, n_iter=40, cv=3, random_state=13, n_jobs=8); # the best model\n",
    "random_search.fit(X_train, y_train);\n",
    "\n",
    "print(\"Optimal parameters:\", random_search.best_params_); # \n",
    "print(\"Train accuracy: %.3f\" %random_search.score(X_train, y_train));\n",
    "print(\"Test accuracy: %.3f\" %random_search.score(X_val, y_val));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit model w/ the best params (RandomizedSearchCV already does this)\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, min_samples_split=0.1, max_depth=11.0, learning_rate=0.25, verbose=2); \n",
    "gbc.fit(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypred = random_search.predict_proba(X_test)[:,1]\n",
    "ypred = gbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Create submission file.\n",
    "submission = pd.DataFrame(ypred, columns=['prediction']) # Create new dataframe.\n",
    "submission['Id'] = submission.index  # Kaggle expects two columns: Id, prediction.\n",
    "submission.to_csv('ps2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
